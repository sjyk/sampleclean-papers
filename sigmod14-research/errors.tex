\section{Queries and Parameters}
For each of our supported queries, the specifics of the cleaning determine the algorithm parameters.
As discussed in the previous section, we want to construct the functions $\phi(.)$ and $f(.)$ in such a way that we obtain an unbiased estimator and analytic CLT error bars for our desired aggregator.
Recall, that we support three cleaning operations: correcting aggregation errors, identifying false positives, and merging duplicates.
These operations are not mutually exclusive and real data may contain all three types of errors (numerical, false positive, and duplication).

That said, we will incrementally derive the parameters for these operations.
We will start with data that only contains aggregation errors, then consider data that contains both aggregation errors and false positive errors, and finally consider errors that may also include duplication.
The derivation will show the dependencies of the estimators on various aspects of the data independent of other error types (e.g., error variance, false positive rate, duplication rate).  
To keep our data type consistent (tuples vs. numerical attribute), most of the $f(.)$ functions will have a term $t[j]$.
Recall from (Section ???), that this means we are extracting the j-th numerical attribute from the tuple $t$ and we are only considering single dimensional aggregations.

\subsection{Numerical Errors}
First, let us consider the simplest case when the tuples only have aggregation errors.
In this model, we can see that if $\phi(.)$ assigns a correct value to any incorrect tuples $\phi(t_i)= t_i^{(c)}$, then the result will be in expectation the aggregation of the clean data.
\begin{table}[!ht]
\caption{Algorithm Parameters for data with only aggregation errors}
\centering 
\begin{tabular}{c c c c}
\hline\hline
Query & $\phi(.)$ & $f(.)$ \\ 
\hline  % inserts single horizontal line
$\textbf{avg}$ & $\phi(t_i)=t_i^{(c)}$ &$f(t)=t[j]$ \\ % inserting body of the table
$\textbf{sum}$ & $\phi(t_i)=t_i^{(c)}$ & $f(t))=Nt[j]$ \\
$\textbf{count}$ & $\phi(t_i)=t_i^{(c)}$ & $f(t)= N$ \\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\end{table}

\subsection{False Positive Errors}
Now, we can extend the previous analysis to the case when some tuples are false positives.
In this case, we want to make sure we don't include their contributions into the aggregations.
This leads to the intuitive choice of $\phi(.)$, which sets the aggregation attributes of tuples that don't satisfy the predicate to zero.
This means that that \textbf{sum} and \textbf{count} will be correct and the mean will be correct up to a proportionality constant of the fraction of tuples zeroed in the sample $r$.

\begin{table}[!ht]
\caption{Algorithm Parameters for data with aggregation errors and false positive errors}
\centering 
\begin{tabular}{c c c c}
\hline\hline
Query & $\phi(.)$ & $f(.)$ \\ 
\hline  % inserts single horizontal line
$\textbf{avg}$ & $\phi(t_i)=\left\{
	\begin{array}{ll}
		t_i^{(c)}  & \mbox{if } \text{predicate} \\
		0 & \text{otherwise}
	\end{array}
\right.$ & $f(t)=\frac{1}{r}t[j]$ \\ % inserting body of the table
$\textbf{sum}$ & $\phi(t_i)=\left\{
	\begin{array}{ll}
		t_i^{(c)}  & \mbox{if } \text{predicate} \\
		0 & \text{otherwise}
	\end{array}
\right.$ & $f(t)=Nt[j]$ \\
$\textbf{count}$ & $\phi(t_i)=\left\{
	\begin{array}{ll}
		1 & \mbox{if } \text{predicate} \\
		0 & \text{otherwise}
	\end{array}
\right.$ & $f(t)=Nt[j]$ \\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\end{table}

\subsection{Duplication Errors}
Duplication errors are particularly troublesome since they affect the sampling properties of the dataset.
If a tuple has been duplicated, then it will be over represented in random sample.
For our set of supported aggregation functions, we can use a reweighting technique to address the problem of duplication.

A more detailed proof and discussion can be found in the appendix, but for intuition consider the definition of the
discrete expected value function:
\[\mathbb{E}(x)=\sum_{x=-\infty}^{\infty}x\mathbb{P}(X=x) \]
If a data item with value $x$ is duplicated, it affects $\mathbb{P}(X=x)$ by the number of times it has been duplicated $m$.
If we know $m$ we can reweight $x'=\frac{x}{m}$, so that in the aggregation it cancels out the additional contribution.
Basically, the end result is that up-to some scaling we can acheive an estimate that is unbiased even if we merge some duplicate values.

Similar to our definition of $r$ in our discussion of the false positive errors, we introduce a variable $d$ to be the duplication rate of a sample $d=\frac{\text{total}}{\text{unique}}$.

\begin{table}[!ht]
\caption{Algorithm Parameters for data with all three errors}
\centering 
\begin{tabular}{c c c c}
\hline\hline
Query & $\phi(.)$ & $f(.)$ \\ 
\hline  % inserts single horizontal line
$\textbf{avg}$ & $\phi(t_i)=\left\{
	\begin{array}{ll}
		\frac{t_i^{(c)}}{m_i}  & \mbox{if } \text{predicate} \\
		0 & \text{otherwise}
	\end{array}
\right.$ & $f(t)=\frac{d}{r}t[j]$ \\ % inserting body of the table
$\textbf{sum}$ & $\phi(t_i)=\left\{
	\begin{array}{ll}
		\frac{t_i^{(c)}}{m_i}  & \mbox{if } \text{predicate} \\
		0 & \text{otherwise}
	\end{array}
\right.$ & $f(t)=Nt[j]$ \\
$\textbf{count}$ & $\phi(t_i)=\left\{
	\begin{array}{ll}
		\frac{1}{m_i} & \mbox{if } \text{predicate} \\
		0 & \text{otherwise}
	\end{array}
\right.$ & $f(t)=Nt[j]$ \\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\end{table}