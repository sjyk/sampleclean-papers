\vspace{-1em}
\section{Related Work}\label{related}
\vspace{-.3em}

Addressing the cost of materialized view maintenance is the subject of many recent papers, which
focus on various perspectives including complex analytical queries~\cite{nikolic2014linview}, transactions~\cite{bailis2014scalable}, real-time analytics \cite{liarou2012monetdb}, and physical design~\cite{lefevre2014opportunistic}.
%The increased research focus parallels a major concern in industrial systems for incrementally updating pre-computed results and indices such as Google Percolator~\cite{percolator} and Twitter's Rainbird~\cite{rainbird}.
The streaming community has also studied the view maintenance problem \cite{abadi2003aurora,golab2012scalable, he2010comet, ghanem2010supporting, KrishnamurthyFDFGLT10}. 
%In Spark Streaming, Zaharia et~al. studied how they could exploit in-memory materialization~\cite{zaharia2012discretized}, and in MonetDB, Liarou et~al. studied how ideas from columnar storage can be applied to enable real-time analytics \cite{liarou2012monetdb}.
%These works focus on correctness, consistency, and fault tolerance of materialized view maintenance.
\svc proposes an alternative model where we allow approximation error (with guarantees) for queries on materialized views for vastly reduced maintenance time.
%In many decision problems, exact results are not needed as long as the probability of error is boundable. 


Sampling has been well studied in the context of query processing~\cite{AgarwalMPMMS13, olken1993random, garofalakis2001approximate}. 
Both the problems of efficiently sampling relations \cite{olken1993random} and processing complex queries \cite{agarwalknowing}, have been well studied. 
In \svc, we look at a new problem, where we efficiently sample from a maintenance strategy, a relational expression that updates a materialized view.
We generalize uniform sampling procedures to work in this new context using lineage \cite{DBLP:journals/vldb/CuiW03} and hashing.
We look the problem of approximate query processing \cite{AgarwalMPMMS13, agarwalknowing} from a different perspective by estimating a ``correction'' rather than estimating query results. 
Srinivasan and Carey studied a problem related to query correction which they called compensation-based query processing \cite{srinivasanC92} for concurrency control but did not study this for sampled estimates.
%This work was applied in the context of concurrency control.
%However, this work did not consider applications when the correction was applied to a sample as in \svc.
%The sampling in \svc introduces new challenges such as sensitivity to outliers, questions of bias, and estimate optimality. 

Sampling has also been studied from the perspective of maintaining samples \cite{DBLP:conf/icde/OlkenR92}.
In~\cite{joshi2008materialized}, Joshi and Jermaine studied indexed materialized views that are amenable to random sampling.
While similar in spirit (queries on the view are approximate), the goal of this work was to optimize query processing not address the cost of incremental maintenance.
There has been work using sampled views in a limited context of cardinality estimation \cite{larson2007cardinality}, which is the special case of our framework, namely, the \countfunc query.
Nirkhiwale et al. \cite{DBLP:journals/pvldb/NirkhiwaleDJ13}, studied an algebra for estimating confidence intervals in aggregate queries.
The objective of this work is not sampling efficiency, as in \svc, but estimation.
As a special case, where we consider only views constructed from select and project operators, \svc's hash pushdown will yield the same results as their model.
There has been theoretical work on the maintenance of approximate histograms, synopses, and sketches ~\cite{gibbons1997fast, DBLP:journals/ftdb/CormodeGHJ12}, which closely resemble aggregate materialized views.
The objectives of this work (including techniques such as sketching and approximate counting) has been to reduce the required storage, not to reduce the required update time.

Meliou et al. \cite{DBLP:conf/sigmod/MeliouGNS11} proposed a technique to trace errors in an MV to base data and find responsible erroneous tuples. 
They do not, however, propose a technique to correct the errors as in \svc.
Correcting general errors as in Meliou et al. is a hard constraint satisfaction problem.
However, in \svc, through our formalization of staleness, we have a model of how updates to the base data (modeled as errors) affect MVs, which allows us to both trace errors and clean them.
Wu and Madden \cite{DBLP:journals/pvldb/0002M13} did propose a model to correct ``outliers" in an MV through deletion of records in the base data.
This is a more restricted model of data cleaning than \svc, where the authors only consider changes to existing rows in an MV (no insertion or deletion) and does not handle the same generality of relational expressions (e.g., nested aggregates).
Challamalla et al. \cite{DBLP:conf/sigmod/ChalamallaIOP14} proposed an approximate technique for specifying errors as constraints on a materialized view and proposing changes to the base data such that these constraints can be satisfied.
While complementary, one major difference between the three works \cite{DBLP:conf/sigmod/MeliouGNS11, DBLP:journals/pvldb/0002M13, DBLP:conf/sigmod/ChalamallaIOP14} and \svc is that they require an explicit specification of erroneous rows in a materialized view.
Identifying whether a row is erroneous requires materialization and thus specifying the errors is equivalent to full incremental maintenance. 
We use the formalism of a ``maintenance strategy", the relational expression that updates the view, to allow us to sample rows that are not yet materialized.
However, while not directly applicable for staleness, we see \svc as complementary to these works in the dirty data setting. 
The sampling technique proposed in Section 4 of our paper could be used to approximate the data cleaning techniques in \cite{DBLP:conf/sigmod/MeliouGNS11, DBLP:journals/pvldb/0002M13, DBLP:conf/sigmod/ChalamallaIOP14} and this is an exciting avenue of future work.

%Sampling has been explored in the streaming community, and a similar idea of sampling from incoming updates has also been applied in stream processing~\cite{tatbul2003load, Garofalakis, rabkin2014aggregation}.
%While some of these works studied problems similar to materialization, for example, the JetStream project (Rabkin et al.) looks at how sampling can help with real-time analysis of aggregates.
%None of these works formally studied the class views that can benefit from sampling or formalized queries on these views.
%However, there are ideas from Rabkin et al. that could be applied in \svc in future work, for example, their description of coarsening operations in aggregates is very similar to our experiments with the ``roll-up'' queries in aggregate views.
%There are a variety of other efforts proposing storage efficient processing of aggregate queries on streams \cite{dobra2002processing, greenwald2001space} which is similar to our problem setting and motivation.


%There is also close relationship between sampling and probabilistic databases, and view maintenance and selection in the context of probabilistic databases have also been studied \cite{re2007materialized}.
%While this line work studies query processing on probabilistic views, it does not study their maintenance as in \svc.
\vspace{-1em}
\section{Limitations and Opportunities}\vspace{-.3em}\label{sec:disc}
While our experiments show that \svc works for a variety applications, there are a few limitations which we summarize in this section.
There are two primary limitations for \svc: class of queries and types of materialized views.
In this work, we primarily focused on aggregate queries and showed that accuracy decreases as the selectivity of the query increases.
Sampled-based methods are fundamentally limited in the way they can support ``point lookup" queries that select a single row.
This is predicted by our theoretical result that accuracy decreases with $\frac{1}{p}$ where $p$ is the fraction of rows that satisfy the predicate.
In terms of more view definitions, \svc does not support views with ordering or ``top-k'' clauses, as our sampling assumes no ordering on the rows of the MV and it is not clear how sampling commutes with general ordering operations.
In the future, we will explore maintenance optimizations proposed in recent work.
For example, DBToaster has two main components, higher-order delta processing and a SQL query compiler, both of which are complementary to \svc.
%\svc proposes a new approach for accurate query processing with MVs.
%Our results are promising and suggest many avenues for future work.
%In particular, we are interested in deeper exploration of the multiple MV setting.
%There are many interesting design problems such as given storage constraints and throughput demands, optimize sampling ratios over all views.
%Furthermore, there is an interesting challenge about queries that join mutliple sample MVs managed by \svc.
%We are also interested in the possibility of sharing computation between MVs and maintenance on views derived from other views.
%Finally, our results suggest relatively a straight forward implementation of adaptive selection of the parameters in \svc such as the view sampling ratio and the outlier index threshold.

\vspace{-1em}
\section{Conclusion}\label{conclusion}
\vspace{-.3em}
%In this paper, we propose a new framework, \svc, to address the staleness problem in materialized views.
Materialized view maintenance is often expensive, and in practice, eager view maintenance is often avoided due to its costs.
This leads to stale materialized views which have incorrect, missing, and superfluous rows.
In this work, we formalize the problem of staleness and view maintenance as a data cleaning problem.
\svc uses a sample-based data cleaning approach to get accurate query results that reflect the most recent data for a greatly reduced computational cost.
To achieve this, we significantly extended our prior work in data cleaning, SampleClean \cite{wang1999sample}, for efficient cleaning of stale MVs. 
This included processing a wider set of aggregate queries, handling missing data errors, and proving for which queries optimality of the estimates hold.
We presented both empirical and theoretical results showing that our sample data cleaning approach is significantly less expensive than full view maintenance for a large class of materialized views, while still providing accurate aggregate query answers that reflect the most recent data.





