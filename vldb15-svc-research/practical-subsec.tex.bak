\subsection{Error Bars and Optimality}\label{subsec:correct-practical}
The only terms in the correction that are not deterministic is $\dans$ and $\dans_{cnt}$.
For the \sumfunc, \countfunc, and \avgfunc queries, we can bound these terms in error bars thus giving us error bars for the entire expression (refer to \cite{wang1999sample} on how to do this).
The intuition is that we can rewrite the term $\dans$ as a mean value of uniformly randomly sampled records.
By the Central Limit Theorem, the mean value of numbers drawn by uniform random sampling $\bar{X}$ approaches a normal distribution with:
\[
\bar{X} \sim N(\mu,\frac{\sigma^2}{k}),
\]
where $\mu$ is the true mean, $\sigma^2$ is the variance, and $k$ is the sample size. \footnote{For sampling without replacement, there is an additional term of $\sqrt{\frac{N-k}{N-1}}$. We consider estimates where N is large in comparision to k making this term insignificant.}
We can use this to bound the term with its 95\% confidence interval (or any other user specified probability), e.g., $\bar{X} \pm 1.96 \frac{\sigma}{\sqrt{k}}$.
Since the estimate is unbiased, the confidence interval indicates that the true value lies in the confidence interval with the specified probability.

We can prove that for the \sumfunc, \countfunc, and \avgfunc queries this estimate is optimal with respect to the variance.
\begin{proposition}
An estimator is called a minimum variance unbiased estimator (MVUE) of a parameter if it is unbiased and the variance of the parameter estimate is less than or equal to that of any other unbiased estimator of the parameter.
\end{proposition}
The concept of a Minimum Variance Unbiased Estimator (MVUE) comes from statistical decision theory \cite{cox1979theoretical}.
Unbiased estimators are ones that, in expectation, are correct.
However, on its own, the concept of an unbiased estimate is not useful as we can construct bad unbiased estimates.
For example, if we simply pick a random element from a set, it is still an unbiased estimate of the mean of the set.
The variance of the estimate determines the size of our confidence intervals thus is important to consider.

The \sumfunc, \countfunc, and \avgfunc queries are linear functions of their input rows.
We explored whether our estimate was optimal for linear estimates, for example, should we weight our functions when applied to the sample.
It turns out that the proposed corrections are the optimal strategy when nothing is known about the data distribution a priori.

\begin{theorem}
For \sumfunc, \countfunc, and \avgfunc queries, our estimate of the correction is optimal over the class of linear estimators when no other information is known about the distribution. 
In other words, there exists no other linear function of the set input rows $\{ X_i \}$ that gives a lower variance correction.
\end{theorem}
\begin{proof}
We can reformulate \sumfunc, \countfunc, and \avgfunc as means over the entire table. \sumfunc is the mean multiplied by the dataset size, and \countfunc
is the sum where all the records have been set to 1. Then, we prove the theorem by induction. 
Suppose, we have two estimates of the mean $\bar{X}_1$ and $\bar{X}_2$ with unknown variance and we want to merge them into one estimate $\bar{X} = c_1\bar{X}_1+c_2\bar{X}_2$.
Since, we do not know anything about the distribution by symmetry $c_1 = c_2 = 0.5$. 
Thus we can recursively induct, and we find that if we do not know the variance of data, as is impossible with new updates, then equally weighting all input rows is optimal. 
The full proof can be found in \reminder{Extended Paper}
\end{proof}

\subsection{Extension to Select Queries}
Sample-based approaches are inherrently focus on aggregate queries.
For general Select queries, both SAQP and SVC have limitations.
However, we find that SVC can provide more support for Select queries in comparison to SAQP and no maintenance.
Suppose, we have a Select query of the following form:
\begin{lstlisting} [mathescape]
SELECT * FROM View 
WHERE Condition(A);
\end{lstlisting}
In SVC, we first apply the query to the old view getting a stale result.
Then, we apply the query to the update pattern sample, getting a sample of records that satisfy the condition.
If we take a union of the two results there are some rows that are missing from Select due to the sampling.
We can then rewrite this query as \countfunc to get an estimate of the up-to-date size of the result; giving us a bound on 
the number of missing rows.

In comparison to no maintenance, since we are only adding rows that from our sample is always more accurate.
In comparision to SAQP, we leverage the existing stale view to use the exact selection up-to the last maintenance time avoiding estimating the entire result from the sample.
Of course, this approach is not suited for highly selective queries which are unlikely to have sufficient representation in a sample.
